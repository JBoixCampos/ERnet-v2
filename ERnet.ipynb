{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AJQiAMTJ9oN"
      },
      "source": [
        "# ERnet Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liwgBQHDZsn7"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n3Rl9rNYUDb"
      },
      "outputs": [],
      "source": [
        "!pip install sknw timm einops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u4p9riiJ9oO"
      },
      "source": [
        "## Download files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daPfApKTJ9oO"
      },
      "outputs": [],
      "source": [
        "# architectures\n",
        "!mkdir -p archs\n",
        "!wget https://raw.githubusercontent.com/charlesnchr/ERnet-v2/main/Training/archs/swinir_rcab_arch.py -P archs\n",
        "!wget https://raw.githubusercontent.com/charlesnchr/ERnet-v2/main/Training/archs/rcan_arch.py -P archs\n",
        "\n",
        "# models\n",
        "!mkdir -p models\n",
        "!wget https://github.com/charlesnchr/ERnet-v2/releases/download/v2.0/20220306_ER_4class_swinir_nch1.pth -P models\n",
        "\n",
        "# image files\n",
        "!mkdir -p images\n",
        "!wget https://github.com/charlesnchr/ERnet-v2/releases/download/v2.0/TestImage1.png -P images\n",
        "!wget https://github.com/charlesnchr/ERnet-v2/releases/download/v2.0/TestImage2.png -P images\n",
        "!wget https://github.com/charlesnchr/ERnet-v2/releases/download/v2.0/TestImage3-stack.tif -P images\n",
        "!wget https://github.com/charlesnchr/ERnet-v2/releases/download/v2.0/TestImage4-stack.tif -P images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjKGNNcpZ1Xi"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBvGPZBqZ3Fa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import time \n",
        "\n",
        "import torch.nn as nn\n",
        "from PIL import Image, ImageFile\n",
        "from skimage import io,exposure,img_as_ubyte\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from argparse import Namespace\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import sys\n",
        "import tqdm\n",
        "import pprint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnNe5Pb4ZxG2"
      },
      "source": [
        "# Initialise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuOrX4iCGRTz"
      },
      "source": [
        "### Load ERnet Swin architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Crduc1_4GQ2-"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"archs\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "from swinir_rcab_arch import SwinIR_RCAB\n",
        "from rcan_arch import RCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haRJ-V39iuEQ"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LcNOeqlViYJ"
      },
      "outputs": [],
      "source": [
        "toTensor = transforms.ToTensor()  \n",
        "toPIL = transforms.ToPILImage()      \n",
        "\n",
        "\n",
        "def remove_dataparallel_wrapper(state_dict):\n",
        "\tr\"\"\"Converts a DataParallel model to a normal one by removing the \"module.\"\n",
        "\twrapper in the module dictionary\n",
        "\n",
        "\tArgs:\n",
        "\t\tstate_dict: a torch.nn.DataParallel state dictionary\n",
        "\t\"\"\"\n",
        "\tfrom collections import OrderedDict\n",
        "\n",
        "\tnew_state_dict = OrderedDict()\n",
        "\tfor k, vl in state_dict.items():\n",
        "\t\tname = k[7:] # remove 'module.' of DataParallel\n",
        "\t\tnew_state_dict[name] = vl\n",
        "\n",
        "\treturn new_state_dict\n",
        "\n",
        "\n",
        "def changeColour(I): # change colours (used to match WEKA output, request by Meng)\n",
        "    Inew = np.zeros(I.shape + (3,)).astype('uint8')\n",
        "    for rowidx in range(I.shape[0]):\n",
        "        for colidx in range(I.shape[1]):\n",
        "            if I[rowidx][colidx] == 0:\n",
        "                Inew[rowidx][colidx] = [198,118,255]\n",
        "            elif I[rowidx][colidx] == 127:\n",
        "                Inew[rowidx][colidx] = [79,255,130]\n",
        "            elif I[rowidx][colidx] == 255:\n",
        "                Inew[rowidx][colidx] = [255,0,0]\n",
        "    return Inew\n",
        "\n",
        "\n",
        "\n",
        "def AssembleStacks(basefolder):\n",
        "    # export to tif\n",
        "    \n",
        "    folders = []\n",
        "    folders.append(basefolder + '/in')\n",
        "    folders.append(basefolder + '/out') \n",
        "\n",
        "    for subfolder in ['in','out']:\n",
        "        folder = basefolder + '/' + subfolder\n",
        "        if not os.path.isdir(folder): continue\n",
        "        imgs = glob.glob(folder + '/*.jpg')\n",
        "        imgs.extend(glob.glob(folder + '/*.png'))\n",
        "        n = len(imgs)\n",
        "        \n",
        "        shape = io.imread(imgs[0]).shape\n",
        "        h = shape[0]\n",
        "        w = shape[1]\n",
        "        \n",
        "        if len(shape) == 2:\n",
        "            I = np.zeros((n,h,w),dtype='uint8')\n",
        "        else:\n",
        "            c = shape[2]\n",
        "            I = np.zeros((n,h,w,c),dtype='uint8')\n",
        "        \n",
        "        for nidx, imgfile in enumerate(imgs):\n",
        "            img = io.imread(imgfile)\n",
        "            I[nidx] = img\n",
        "\n",
        "            print('%s : [%d/%d] loaded imgs' % (folder,nidx+1,len(imgs)),end='\\r')\n",
        "        print('')\n",
        "        \n",
        "        stackname = os.path.basename(basefolder)\n",
        "        stackfilename = '%s/%s_%s.tif' % (basefolder,stackname,subfolder)\n",
        "        io.imsave(stackfilename,I,compress=6)\n",
        "        print('saved stack: %s' % stackfilename)\n",
        "\n",
        "\n",
        "\n",
        "def processImage_tiled(net,opt,imgid,img,savepath_in,savepath_out):\n",
        "\n",
        "    imageSize = opt.imageSize\n",
        "\n",
        "    h,w = img.shape[0], img.shape[1]\n",
        "    if imageSize == 0:\n",
        "        imageSize = 250\n",
        "        while imageSize+250 < h and imageSize+250 < w:\n",
        "            imageSize += 250\n",
        "        print('Set imageSize to',imageSize)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')\n",
        "\n",
        "    # img_norm = (img - np.min(img)) / (np.max(img) - np.min(img)) \n",
        "    images = []\n",
        "\n",
        "    images.append(img[:imageSize,:imageSize])\n",
        "    images.append(img[h-imageSize:,:imageSize])\n",
        "    images.append(img[:imageSize,w-imageSize:])\n",
        "    images.append(img[h-imageSize:,w-imageSize:])\n",
        "\n",
        "    proc_images = []\n",
        "    for idx,sub_img in enumerate(images):\n",
        "        # sub_img = (sub_img - np.min(sub_img)) / (np.max(sub_img) - np.min(sub_img))\n",
        "        pil_sub_img = Image.fromarray((sub_img*255).astype('uint8'))\n",
        "        \n",
        "        # sub_tensor = torch.from_numpy(np.array(pil_sub_img)/255).float().unsqueeze(0)\n",
        "        sub_tensor = toTensor(pil_sub_img)\n",
        "\n",
        "        sub_tensor = sub_tensor.unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            sr = net(sub_tensor.to(device))\n",
        "            \n",
        "            sr = sr.cpu()\n",
        "            # sr = torch.clamp(sr,min=0,max=1)\n",
        "\n",
        "            m = nn.LogSoftmax(dim=0)\n",
        "            sr = m(sr[0])\n",
        "            sr = sr.argmax(dim=0, keepdim=True)\n",
        "            \n",
        "            # pil_sr_img = Image.fromarray((255*(sr.float() / (opt.nch_out - 1)).squeeze().numpy()).astype('uint8'))\n",
        "            pil_sr_img = toPIL(sr.float() / (opt.nch_out - 1))\n",
        "\n",
        "            # pil_sr_img.save(opt.out + '/segmeneted_output_' + str(i) + '_' + str(idx) + '.png')\n",
        "            # pil_sub_img.save(opt.out + '/imageinput_' + str(i) + '_' + str(idx) + '.png')\n",
        "\n",
        "            proc_images.append(pil_sr_img)\n",
        "        \n",
        "    # stitch together\n",
        "    img1 = proc_images[0]\n",
        "    img2 = proc_images[1]\n",
        "    img3 = proc_images[2]\n",
        "    img4 = proc_images[3]\n",
        "\n",
        "    woffset = (2*imageSize-w) // 2\n",
        "    hoffset = (2*imageSize-h) // 2\n",
        "\n",
        "    img1 = np.array(img1)[:imageSize-hoffset,:imageSize-woffset]\n",
        "    img3 = np.array(img3)[:imageSize-hoffset,woffset:]\n",
        "    top = np.concatenate((img1,img3),axis=1)\n",
        "\n",
        "    img2 = np.array(img2)[hoffset:,:imageSize-woffset]\n",
        "    img4 = np.array(img4)[hoffset:,woffset:]\n",
        "    bot = np.concatenate((img2,img4),axis=1)\n",
        "\n",
        "    oimg = np.concatenate((top,bot),axis=0)\n",
        "    # crop?\n",
        "    # oimg = oimg[10:-10,10:-10]\n",
        "    # img = img[10:-10,10:-10]\n",
        "    # remove boundaries? \n",
        "    # oimg[:10,:] = 0\n",
        "    # oimg[-10:,:] = 0\n",
        "    # oimg[:,:10] = 0\n",
        "    # oimg[:,-10:] = 0\n",
        "\n",
        "    if opt.stats_tubule_sheet:\n",
        "        npix1 = np.sum(oimg == 170) # tubule\n",
        "        npix2 = np.sum(oimg == 255) # sheet\n",
        "        npix3 = np.sum(oimg == 85) # SBT\n",
        "\n",
        "        npix = npix1+npix2+npix3\n",
        "        opt.csvfid.write('%s,%0.4f,%0.4f,%0.4f\\n' % (imgid,npix1/npix,npix2/npix,npix3/npix))\n",
        "    if opt.weka_colours:\n",
        "        oimg = changeColour(oimg)\n",
        "\n",
        "    Image.fromarray(oimg).save(savepath_out)\n",
        "    if opt.save_input:\n",
        "        io.imsave(savepath_in,img_as_ubyte(img))\n",
        "        \n",
        "    # Image.fromarray((img*255).astype('uint8')).save('%s/input_%04d.png' % (opt.out,i))\n",
        "\n",
        "def processImage(net,opt,imgid,img,savepath_in,savepath_out):\n",
        "\n",
        "    imageSize = opt.imageSize\n",
        "\n",
        "    h,w = img.shape[0], img.shape[1]\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')\n",
        "\n",
        "    # img_norm = (img - np.min(img)) / (np.max(img) - np.min(img)) \n",
        "    pil_sub_img = Image.fromarray((img*255).astype('uint8'))\n",
        "        \n",
        "    # sub_tensor = torch.from_numpy(np.array(pil_sub_img)/255).float().unsqueeze(0)\n",
        "    sub_tensor = toTensor(pil_sub_img)\n",
        "\n",
        "    if 'swin' in opt.weights and 'nch1' not in opt.weights:\n",
        "        sub_tensor = torch.cat((sub_tensor,sub_tensor,sub_tensor),0)\n",
        "    sub_tensor = sub_tensor.unsqueeze(0)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        sr = net(sub_tensor.to(device))\n",
        "        \n",
        "        sr = sr.cpu()\n",
        "        # sr = torch.clamp(sr,min=0,max=1)\n",
        "\n",
        "        m = nn.LogSoftmax(dim=0)\n",
        "        sr = m(sr[0])\n",
        "        sr = sr.argmax(dim=0, keepdim=True)\n",
        "        \n",
        "        # pil_sr_img = Image.fromarray((255*(sr.float() / (opt.nch_out - 1)).squeeze().numpy()).astype('uint8'))\n",
        "        pil_sr_img = toPIL(sr.float() / (opt.nch_out - 1))\n",
        "\n",
        "        # pil_sr_img.save(opt.out + '/segmeneted_output_' + str(i) + '_' + str(idx) + '.png')\n",
        "        # pil_sub_img.save(opt.out + '/imageinput_' + str(i) + '_' + str(idx) + '.png')\n",
        "\n",
        "\n",
        "    oimg = np.array(pil_sr_img)\n",
        "\n",
        "    # workaround for new order of classes\n",
        "    sheet_ind = oimg == 255\n",
        "    SBT_ind = oimg == 85\n",
        "    tubule_ind = oimg == 170\n",
        "    oimg[sheet_ind] = 85\n",
        "    oimg[SBT_ind] = 170\n",
        "    oimg[tubule_ind] = 255\n",
        "\n",
        "    if opt.stats_tubule_sheet:\n",
        "        npix1 = np.sum(oimg == 255) # tubule\n",
        "        npix2 = np.sum(oimg == 85) # sheet\n",
        "        npix3 = np.sum(oimg == 170) # SBT\n",
        "\n",
        "        npix = npix1+npix2+npix3\n",
        "        opt.csvfid.write('%s,%0.4f,%0.4f,%0.4f\\n' % (imgid,npix1/npix,npix2/npix,npix3/npix))\n",
        "    if opt.weka_colours:\n",
        "        oimg = changeColour(oimg)\n",
        "\n",
        "    Image.fromarray(oimg).save(savepath_out)\n",
        "    if opt.save_input:\n",
        "        io.imsave(savepath_in,img_as_ubyte(img))\n",
        "        \n",
        "    # Image.fromarray((img*255).astype('uint8')).save('%s/input_%04d.png' % (opt.out,i))\n",
        "\n",
        "\n",
        "\n",
        "def EvaluateModel(opt):\n",
        "\n",
        "    if opt.stats_tubule_sheet:\n",
        "        # if opt.out == 'root':\n",
        "        #     if opt.root[0].lower() in ['jpg','png','tif']:\n",
        "        #         pardir = os.path.abspath(os.path.join(opt.root,os.pardir))\n",
        "        #         opt.csvfid = open('%s/stats_tubule_sheet.csv' % pardir,'w')\n",
        "        #     else:\n",
        "        #         opt.csvfid = open('%s/stats_tubule_sheet.csv' % opt.root,'w')\n",
        "        # else:\n",
        "        #     opt.csvfid = open('%s/stats_tubule_sheet.csv' % opt.out,'w')\n",
        "        opt.csvfid.write('Filename,Tubule fraction,Sheet fraction,SBT fraction\\n')\n",
        "\n",
        "    if opt.graph_metrics:\n",
        "        opt.graphfid.write('Filename,no_nodes,no_edges,assortativity, clustering, compo, ratio_nodes, \\\n",
        "        ratio_edges, degree 1, degree 2, degree 3, degree 4, degree 5, degree 6\\n')\n",
        "        \n",
        "\n",
        "    if 'swin' not in opt.weights:\n",
        "        print('LOADING: CNN architecture')\n",
        "        # RCAN model\n",
        "        net = RCAN(opt)\n",
        "    elif 'swin3d' in opt.weights:\n",
        "        print('LOADING: Transformer architecture')\n",
        "        # Swin model\n",
        "        patch_size_t = 1 if 'nch1' in opt.weights else 3\n",
        "        opt.task = 'segment'\n",
        "        net = SwinTransformer3D_RCAB(\n",
        "                opt,\n",
        "                patch_size=(patch_size_t,4,4),\n",
        "                in_chans=1,\n",
        "                embed_dim=96,\n",
        "                depths=[2, 2, 6, 2],\n",
        "                num_heads=[3, 6, 12, 24],\n",
        "                window_size=(2,7,7),\n",
        "                mlp_ratio=4.,\n",
        "                qkv_bias=True,\n",
        "                qk_scale=None,\n",
        "                drop_rate=0.,\n",
        "                attn_drop_rate=0.,\n",
        "                drop_path_rate=0.2,\n",
        "                norm_layer=nn.LayerNorm,\n",
        "                patch_norm=True,\n",
        "                upscale=1,\n",
        "                frozen_stages=-1,\n",
        "                use_checkpoint=False,\n",
        "                vis=False\n",
        "            )\n",
        "    elif 'swinir' in opt.weights:\n",
        "        print('LOADING: Transformer architecture')\n",
        "        # Swin model\n",
        "        opt.task = 'segment'\n",
        "        net = SwinIR_RCAB(\n",
        "            opt,\n",
        "            img_size=128,\n",
        "            in_chans=1,\n",
        "            upscale=1,\n",
        "            use_checkpoint=False,\n",
        "            vis=False\n",
        "        )\n",
        "    else:\n",
        "        print('model architecture not inferred')\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')\n",
        "    net.to(device)\n",
        "\n",
        "    checkpoint = torch.load(opt.weights, map_location=device)\n",
        "    print('loading checkpoint',opt.weights)\n",
        "    net.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    if opt.root[0].split('.')[-1].lower() in ['png','jpg','tif']:\n",
        "        imgs = opt.root\n",
        "    else:\n",
        "        imgs = []\n",
        "        for ext in opt.ext:\n",
        "            # imgs.extend(glob.glob(opt.root + '/*.jpg')) # scan only folder\n",
        "            if len(imgs) == 0: # scan everything\n",
        "                for dir in opt.root:\n",
        "                    imgs.extend(glob.glob(dir + '/**/*.%s' % ext,recursive=True))\n",
        "\n",
        "\n",
        "    # find total number of images to process\n",
        "    nimgs = 0\n",
        "    for imgidx, imgfile in enumerate(imgs):\n",
        "        basepath, ext = os.path.splitext(imgfile)\n",
        "\n",
        "        if ext.lower() == '.tif':\n",
        "            img = io.imread(imgfile)\n",
        "            if len(img.shape) == 2: # grayscale \n",
        "                nimgs += 1\n",
        "            elif  img.shape[2] <= 3:\n",
        "                nimgs += 1\n",
        "            else: # t or z stack\n",
        "                nimgs += img.shape[0]\n",
        "        else:\n",
        "            nimgs += 1\n",
        "\n",
        "    outpaths = []\n",
        "    imgcount = 0\n",
        "\n",
        "    # primary loop\n",
        "    for imgidx, imgfile in enumerate(tqdm.notebook.tqdm(imgs)):\n",
        "        basepath, ext = os.path.splitext(imgfile)\n",
        "\n",
        "        if ext.lower() == '.tif':\n",
        "            img = io.imread(imgfile)\n",
        "        else:\n",
        "            img = np.array(Image.open(imgfile))\n",
        "\n",
        "        img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "        img = img.astype('float')\n",
        "\n",
        "\n",
        "        if len(img.shape) > 2 and img.shape[2] <= 3:\n",
        "            print('removing colour channel')\n",
        "            img = np.max(img,2) # remove colour channel\n",
        "\n",
        "        # img = io.imread(imgfile)\n",
        "        # img = (img - np.min(img)) / (np.max(img) - np.min(img)) \n",
        "\n",
        "        # filenames for saving\n",
        "        idxstr = '%04d' % imgidx\n",
        "        if opt.out == 'root': # save next to orignal\n",
        "            savepath_out = imgfile.replace(ext,'_out_' + idxstr + '.png')\n",
        "            savepath_in = imgfile.replace(ext,'_in_' + idxstr + '.png')\n",
        "            basesavepath_graphfigures = imgfile.replace(ext,'')\n",
        "        else: \n",
        "            pass # not implemented\n",
        "\n",
        "        # process image\n",
        "        if len(img.shape) == 2:            \n",
        "            # status\n",
        "            # print(\"Segmentation,%d,%d\" % (imgcount, nimgs))\n",
        "\n",
        "            p1,p99 = np.percentile(img,1),np.percentile(img,99)\n",
        "            print(img.shape,np.max(img),np.min(img))\n",
        "            imgnorm = exposure.rescale_intensity(img,in_range=(p1,p99))\n",
        "            print(imgnorm.shape,np.max(imgnorm),np.min(imgnorm))\n",
        "            imgid = '%s:%s' % (os.path.basename(imgfile),idxstr)\n",
        "            processImage(net,opt,imgid,imgnorm,savepath_in,savepath_out)\n",
        "            \n",
        "            # send result    \n",
        "            outpaths.append(savepath_out)\n",
        "\n",
        "            # graph processing\n",
        "            if graph_metrics:\n",
        "                # print(\"Graph metrics,%d,%d\" % (imgcount, nimgs))\n",
        "\n",
        "                graph_out_paths = performGraphProcessing(savepath_out,opt, basesavepath_graphfigures, imgid)\n",
        "\n",
        "                outpaths.extend(graph_out_paths)\n",
        "\n",
        "            imgcount += 1\n",
        "\n",
        "        else: # more than 3 channels, assuming stack\n",
        "            basefolder = basepath\n",
        "            os.makedirs(basefolder,exist_ok=True)\n",
        "            if opt.save_input:\n",
        "                os.makedirs(basefolder + '/in',exist_ok=True)\n",
        "            if opt.graph_metrics:\n",
        "                os.makedirs(basefolder + '/graph',exist_ok=True)\n",
        "            os.makedirs(basefolder + '/out',exist_ok=True)\n",
        "\n",
        "            for subimgidx in tqdm.notebook.tqdm(range(img.shape[0])):\n",
        "                # status\n",
        "                # print(\"Segmentation,%d,%d\" % (imgcount, nimgs))\n",
        "\n",
        "                idxstr = '%04d_%04d' % (imgidx,subimgidx)\n",
        "                savepath_in = '%s/in/%s.png' % (basefolder,idxstr)\n",
        "                savepath_out = '%s/out/%s.png' % (basefolder,idxstr)\n",
        "                basesavepath_graphfigures = '%s/graph/%s' % (basefolder,idxstr)\n",
        "                p1,p99 = np.percentile(img[subimgidx],1),np.percentile(img[subimgidx],99)\n",
        "                imgnorm = exposure.rescale_intensity(img[subimgidx],in_range=(p1,p99))\n",
        "                imgid = '%s:%s' % (os.path.basename(imgfile),idxstr)\n",
        "                processImage(net,opt,imgid,imgnorm,savepath_in,savepath_out)\n",
        "\n",
        "                # send result                \n",
        "                outpaths.append(savepath_out)\n",
        "\n",
        "                # graph processing\n",
        "                if opt.graph_metrics:\n",
        "                    # print(\"Graph metrics,%d,%d\" % (imgcount, nimgs))\n",
        "\n",
        "                    graph_out_paths = performGraphProcessing(savepath_out,opt, basesavepath_graphfigures,imgid)\n",
        "\n",
        "                    outpaths.extend(graph_out_paths)\n",
        "\n",
        "                imgcount += 1\n",
        "            AssembleStacks(basefolder)\n",
        "\n",
        "\n",
        "    if opt.stats_tubule_sheet:\n",
        "        opt.csvfid.close()\n",
        "\n",
        "    if opt.graph_metrics:\n",
        "        opt.graphfid.close()\n",
        "\n",
        "    print(outpaths)\n",
        "    return outpaths\n",
        "\n",
        "\n",
        "import cv2\n",
        "import sknw\n",
        "from skimage.morphology import skeletonize\n",
        "\n",
        "def remove_isolated_pixels(image):\n",
        "    connectivity = 8\n",
        "\n",
        "    output = cv2.connectedComponentsWithStats(image, connectivity, cv2.CV_32S)\n",
        "\n",
        "    num_stats = output[0]\n",
        "    labels = output[1]\n",
        "    stats = output[2]\n",
        "\n",
        "    new_image = image.copy()\n",
        "\n",
        "    for label in range(num_stats):\n",
        "        if stats[label,cv2.CC_STAT_AREA] < 50:\n",
        "            new_image[labels == label] = 0\n",
        "\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def binariseImage(I):\n",
        "    if len(I.shape) > 2:\n",
        "        ind = I[:,:,0] > 250\n",
        "    else:\n",
        "        ind = I > 250\n",
        "    Ibin = np.zeros((I.shape[0],I.shape[1])).astype('uint8')\n",
        "    Ibin[ind] = 255\n",
        "    Ibin = remove_isolated_pixels(Ibin)\n",
        "    return Ibin\n",
        "\n",
        "\n",
        "def getGraph(img,basename):\n",
        "    img = binariseImage(img) / 255\n",
        "    ske = skeletonize(img).astype(np.uint16)\n",
        "    # ske = img.astype('uint16')\n",
        "\n",
        "    # build graph from skeleton\n",
        "    graph = sknw.build_sknw(ske)\n",
        "\n",
        "    # draw image\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.imshow(img, cmap='gray')\n",
        "\n",
        "    # draw edges by pts\n",
        "    for (s,e) in graph.edges():\n",
        "        ps = graph[s][e]['pts']\n",
        "        plt.plot([ps[0,1],ps[-1,1]], [ps[0,0],ps[-1,0]], 'green')\n",
        "        \n",
        "    # draw node by o\n",
        "    nodes = graph.nodes()\n",
        "    ps = np.array([nodes[i]['o'] for i in nodes])\n",
        "    plt.plot(ps[:,1], ps[:,0], 'r.')\n",
        "\n",
        "    # print('EDGES',graph.edges())\n",
        "    # print('NODES',graph.nodes())\n",
        "    \n",
        "    plt.savefig('%s_fig.jpg' % basename, bbox_inches = 'tight', pad_inches = 0, quality=80,dpi=300)\n",
        "    plt.close()\n",
        "    open('%s_edges.dat' % basename,'w').write(str(graph.edges()).replace('(','[').replace(')',']'))\n",
        "    open('%s_nodes.dat' % basename,'w').write(str(graph.nodes()).replace('(','[').replace(')',']'))\n",
        "\n",
        "    edges = np.array(graph.edges())\n",
        "\n",
        "    return edges, nodes\n",
        "\n",
        "import networkx as nx\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "#build teh networkx graph from node and egdes lists \n",
        "def build_graph(nodes,edges):\n",
        "    G=nx.Graph()\n",
        "    G.add_nodes_from(nodes)\n",
        "    for edge in edges:\n",
        "        G.add_edge(edge[0],edge[1])\n",
        "    return G\n",
        "\n",
        "# perform some analysis \n",
        "def simple_analysis(G):\n",
        "    no_nodes=G.number_of_nodes()\n",
        "    no_edges=G.number_of_edges()\n",
        "    assortativity = nx.degree_assortativity_coefficient(G)\n",
        "    clustering = nx.average_clustering(G)\n",
        "    compo = nx.number_connected_components(G)\n",
        "    Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "    G0 = G.subgraph(Gcc[0])\n",
        "    size_G0_edges = G0.number_of_edges()\n",
        "    size_G0_nodes = G0.number_of_nodes()\n",
        "    ratio_nodes=size_G0_nodes/no_nodes\n",
        "    ratio_edges =size_G0_edges/no_edges\n",
        "    return no_nodes,no_edges,assortativity, clustering, compo, ratio_nodes, ratio_edges\n",
        "\n",
        "# here we generate a histogram of degrees with a specified colour\n",
        "def degree_histogram(savepath,G,colour='blue'):\n",
        "    plt.figure()\n",
        "\n",
        "    degree_sequence = sorted([d for n, d in G.degree()], reverse=True)  # degree sequence\n",
        "    degreeCount = collections.Counter(degree_sequence)\n",
        "    deg, cnt = zip(*degreeCount.items())\n",
        "    fig1, ax = plt.subplots()\n",
        "    plt.bar(deg, cnt, width=0.80, color=colour)\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.xlabel(\"%Degree\")\n",
        "    ax.set_xticks([d + 0.4 for d in deg])\n",
        "    ax.set_xticklabels(deg)\n",
        "    plt.savefig(savepath)\n",
        "    plt.close()\n",
        "\n",
        "    print(deg,cnt)\n",
        "\n",
        "    degrees = [0]*6 # ordered from deg. 1 to 6\n",
        "    for _deg,_cnt in zip(deg,cnt):\n",
        "        if _deg - 1 < 6:\n",
        "            degrees[_deg - 1] = _cnt\n",
        "\n",
        "    return degrees\n",
        "\n",
        "\n",
        "\n",
        "# here we generate an image where nodes are coloured according to their degrees \n",
        "def graph_image(savepath,G):\n",
        "    plt.figure()\n",
        "    node_color = [float(G.degree(v)) for v in G]\n",
        "    nx.draw_spring(G,node_size=10,node_color=node_color)\n",
        "    plt.savefig(savepath)\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "def performGraphProcessing(imgfile,opt, basename, imgid):\n",
        "    \n",
        "    savepath_hist = '%s_hist.png' % basename\n",
        "    savepath_graph = '%s_graph.png' % basename\n",
        "\n",
        "    img = io.imread(imgfile)\n",
        "    edges, nodes = getGraph(img, basename)\n",
        "    G=build_graph(nodes,edges)\n",
        "    # metrics: no_nodes,no_edges,assortativity, clustering, compo, ratio_nodes, ratio_edges\n",
        "    metrics = simple_analysis(G)\n",
        "    degrees = degree_histogram(savepath_hist,G,'goldenrod')\n",
        "    graph_image(savepath_graph,G)\n",
        "\n",
        "    opt.graphfid.write('%s,%d,%d,%0.5f,%0.5f,%0.5f,%0.5f,%0.5f,%d,%d,%d,%d,%d,%d\\n' % (imgid,*metrics,*degrees))\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    return [savepath_graph,savepath_hist]\n",
        "\n",
        "\n",
        "\n",
        "def segment(exportdir,filepaths,weka_colours,stats_tubule_sheet,graph_metrics,save_in_original_folders,save_input=True):\n",
        "    opt = Namespace()\n",
        "    opt.root = filepaths\n",
        "    opt.ext = ['jpg','png','tif']\n",
        "    opt.stats_tubule_sheet = stats_tubule_sheet\n",
        "    opt.graph_metrics = graph_metrics\n",
        "    opt.weka_colours = weka_colours\n",
        "    opt.save_input = save_input\n",
        "    \n",
        "    opt.exportdir = exportdir\n",
        "    os.makedirs(exportdir,exist_ok=True)\n",
        "    opt.jobname = datetime.datetime.utcnow().strftime('%Y%m%d%H%M%S%f')[:-3]\n",
        "\n",
        "    if stats_tubule_sheet:\n",
        "        csvfid_path = '%s/%s_stats_tubule_sheet.csv' % (opt.exportdir, opt.jobname)\n",
        "        opt.csvfid = open(csvfid_path,'w')\n",
        "    \n",
        "    if opt.graph_metrics:\n",
        "       graphfid_path = '%s/%s_graph_metrics.csv' % (opt.exportdir, opt.jobname)\n",
        "       opt.graphfid = open(graphfid_path,'w')\n",
        "\n",
        "\n",
        "    ## model specific \n",
        "    opt.imageSize = 600\n",
        "    opt.n_resblocks = 10\n",
        "    opt.n_resgroups = 3\n",
        "    opt.n_feats = 64\n",
        "    opt.reduction = 16\n",
        "    opt.narch = 0\n",
        "    opt.norm = None\n",
        "    opt.nch_in = 1\n",
        "    opt.nch_out = 4\n",
        "    opt.cpu = False\n",
        "    opt.weights = model\n",
        "    opt.scale = 1\n",
        "    \n",
        "    \n",
        "    if save_in_original_folders:\n",
        "        opt.out = \"root\"\n",
        "\n",
        "    # pprint.pprint(vars(opt))\n",
        "    print(vars(opt))\n",
        "    \n",
        "    return EvaluateModel(opt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8vadne_aaDF"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwxb4fJ8YP4v"
      },
      "source": [
        "## Example of using ERnet Transformer on single images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pde0bWrnYP4w"
      },
      "outputs": [],
      "source": [
        "exportdir = 'output'\n",
        "filepaths = ['images/TestImage1.png','images/TestImage2.png']\n",
        "model = 'models/20220306_ER_4class_swinir_nch1.pth'\n",
        "weka_colours = False\n",
        "stats_tubule_sheet = True\n",
        "graph_metrics = True\n",
        "save_in_original_folders = True\n",
        "outpaths = segment(exportdir,filepaths,weka_colours,stats_tubule_sheet,graph_metrics,save_in_original_folders,model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXPU8FCyYP4y",
        "tags": []
      },
      "source": [
        "### Visualise result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3ms6jaGYP4z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# output files per input file\n",
        "n = len(outpaths)//len(filepaths)\n",
        "\n",
        "for idx, inpath in enumerate(filepaths):\n",
        "\n",
        "    outpath = [outpaths[i] for i in range(idx*n, (idx+1)*n )]\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(io.imread(inpath))\n",
        "    plt.title('Input %d: %s' % (idx+1,inpath))\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(io.imread(outpath[0]))\n",
        "    plt.title('Output %d' % (idx+1))\n",
        "\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(io.imread(outpath[1]))\n",
        "    plt.title('Graph representation %d' % (idx+1))\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(io.imread(outpath[2]))\n",
        "    plt.title('Degree histogram %d' % (idx+1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1CpyiRHLp6a"
      },
      "source": [
        "## Example of batch processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXeTfPg-Lp6b"
      },
      "outputs": [],
      "source": [
        "exportdir = 'output'\n",
        "filepaths = ['images/TestImage3-stack.tif','images/TestImage4-stack.tif']\n",
        "model = 'models/20220306_ER_4class_swinir_nch1.pth'\n",
        "weka_colours = False\n",
        "stats_tubule_sheet = True\n",
        "graph_metrics = True\n",
        "save_in_original_folders = True\n",
        "outpaths = segment(exportdir,filepaths,weka_colours,stats_tubule_sheet,graph_metrics,save_in_original_folders,model)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Wdav5aChaWr7",
        "0khBXikThClT",
        "7j6l8aRGZYF6"
      ],
      "name": "ERnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}